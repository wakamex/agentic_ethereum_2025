Hello everyone. I'm Ganesh Swami, I'm one of the co-founders of Covalent. And today I'm going to do a quick walk through the AI Agent SDK.

This is a TypeScript SDK that we've built for developers and you can use this SDK to launch agents. So these agents are uh can perform any kind of task, but it's not just these agents, you can also make these agents autonomous. And we're introducing this concept known as a zero employee enterprise, ZEE in short. And what this does is that it uh brings together this swarm of agents that can iteratively and collaboratively, collaboratively solve any uh kind of complex problem.

Uh and you can see uh all of the inner workings of uh of of how these agents are able to collaborate. And so this is relying on a technique called chain of thought models. This is a new way of using these LLMs. So uh what you're doing is you, just like if you would to ask someone, uh give me a solution to a math problem, uh they're not going to give you like a Google search result, right? Google search results you type in a query, it gives you an instantaneous result. Uh here what it does is they probably go away and then take a couple of minutes, couple of hours and then work through a couple of solutions, uh think through the problem, reason through the problem and then uh suggest a solution. And if it's not able to provide a solution, it's able to show you uh the inner workings of how far it was able to get. So that's basically what's happening with this new form of LLMs. And so we rely on this technique to have these agents uh basically ping pong and challenge each other and bring autonomy to their inner workings. And this is what makes them uh super exciting.

So, uh let's jump right into the code. So the first thing I would uh ask you to do is this agent SDK is fresh off the press. Uh we literally just released this as open source uh today. And so uh the first thing I would recommend you read is the blog post that announces the ZEE concept. And so I'm going to share my screen now and then the rest of the uh this recording will have with uh screen share.

And so this blog post is just on the covalent HQ.com. So you can just go to the blog and see this is the agent um SDK version 2. Uh you know we've had to rebuild this SDK from the ground up because a lot of the assumptions we've made um uh during build or during the like the first version of the SDK, which by the way was only in December and crypto AI agents all this stuff moves like so fast. So you have to uh rethink and uh uh you know challenge your assumptions at all points. So this is basically telling you what's going on here. Uh we've doubled down on the crypto use cases as opposed to building a generalized um you know AI uh agent tool. And so uh it just tells you how you can do all of this stuff. And then the next thing what you need to do is you need to go to the uh to the GitHub uh repo. So this is uh right here.

Actually, before going to the GitHub repo, I would recommend you go to the docs, which gives you an overview. So go to cxt.build and this is the overview of how the SDK works, uh the different components, how do you actually build an agent, how do you piece together tools, uh and how do you build uh a ZEE workflow. So let's walk through some of the concepts here.

So the first concept is uh an LLM, right? So what an LLM does is it's just a thin wrapper over one of the language models. But the beautiful thing here is uh you're able to access about a dozen different LLMs. So what you see here uh is the Open AI LLM, Deepseek, Grot, Gemini and then they obviously take different environment variables. And so you literally just have to uh initialize an LLM with the provider and with the the name of the actual model. So that's what's uh pretty uh interesting about this. Uh the second thing you need to, second concept you need to be uh aware of is what is known as an agent. And so an agent basically has a name, it uh obviously uses a model. Uh it has a description of what the agent is supposed to do and a set of instructions uh on, you know, uh what is the uh what is the basis of this agent. And so here this specific agent, this example is a reporting agent, uh relies on uh Open AI's uh 4.0 Mini and this agent is responsible for generating reports and uh it generates a report on the current state of the company. So that's basically how an agent does. Now what's also special is that these agents are completely stateless, which means they don't have any kind of memory or something. And so here uh or they cannot really access the outside world. And so here this is where you would add tools. So you would just uh go add some tools. We have uh one tool currently built, but there's a lot more being built behind the scenes and you're also welcome to contribute tools to uh the the SDK. So one of the tools we have is the Gold Rush onchain data tool. And so this allows you to get token balances, NFT holdings, transaction history, all kinds of things. And so when you go back to the agent and you give it the tools, then what the agent is able to do when you run the agent using agent.run, it's able to uh try it's it's able to solve the problem and the instructions that you've given, uh but also use these external tools. So it's important to describe these tools in a very uh you know, in a very descriptive way so that the LLM knows, okay, at this point, I have access to this tool and therefore I can basically outsource the thinking to this tool. And then the framework automatically calls this, it's basically function calling. Um and uh so that's like the cool thing about this uh this uh the agent stuff. Uh and here this is some description on, you know, what the tools can do. And not only can it call external APIs uh like the Gold Rush um API, the Gold Rush API uh gives you access to about 100 different blockchains. Uh it's also another covalent product. But the other beautiful thing is that it can also structure the output from uh these these um these agents. Uh so this is how you create a tool, you create a schema and so on. And then the most exciting thing is actually the ZEE workflow. So what the ZEE workflow does is you combine a set of agents and then you give it some kind of like goal and then what essentially this workflow does is internally it has a router that uh basically does uh ping pong between the different uh agents and their respective tools. And uh any kind of memory that is uh stored is stored on the ZEE layer. Uh and so uh in theory what you can do is you can actually use uh Gemini for let's say a multi-model agent and then you can use uh uh let's say uh deep seek because it's really good at certain set of problems. And you can actually get these two uh models actually speak to each other and ping pong uh you know and iterate and then solve this problem. And so that's really what's cool about uh this whole thing.

And then uh what I I jump to the actual repo and give you a lay of the land. All of this is open source. So uh what we are looking is to uh get builders to either build using SDK or directly contribute to the SDK. So I'll get into the layer of the uh of the repo in a bit. So here what we have is um this this thing is completely open. So just go to covalent HQ.com, AI agent SDK. It's also linked from uh the blog post, it's lots of linked from cxt.build. Uh it should be everywhere. It's from the covalent homepage. Uh it's hard to miss. you know, if if you miss if you're if you still miss it, I think we've uh done a bad job here. But you know, it's it's available, it's uh easily accessible and then you can outsource this. Uh you saw you can you can uh you can uh check out this this code and then build it yourself and so on. So, uh what this does is uh basically you can go to the the packages and within the packages, you have the AI agent SDK and then you can uh look at the source and then you have all of these uh LLMs, you have the base and the state. So let's take for example, you want to contribute a new LLM. So go to the LLM and then you open up index.ts. And so what you see here is you have some definitions for Open AI's models, uh Deepseek models, Grot model, Gemini model. Uh and then you know it's missing anthropic. Anthropic is another fantastic model. It's uh missing other kinds of like hosted models. Uh maybe even uh uh so another nice contribution could be is uh refer to Akash's uh inference API or one of the other providers out there. Uh Lama is another really cool kind of model. And so that is another something you can contribute to. And then something else you can contribute to is you go back to uh the tools and then you have the list of tools, right? So here we have the Gold Rush uh tool. So for NFT balances, token balances and transactions and so on. Uh but you can add any other kind of tool, right? Let's say uh you want to add a tool to do uh contract signing or you want to check the uh a tool to um maybe uh verify if the particular transaction is safe, all kinds of things, right? So that's something definitely we're looking to build a big library of tools. And then there's uh a bunch of other stuff, for example, there's the actual like workflow uh in the ZEE folder. So that's basically the workflow, how it iterates through the problems. And then you have um the agent itself. So this is uh basically how like all of the materials inside uh inside the agent including the routers and so on. So that's basically what's going on with the the repo. The documentation uh is also available here. So you go to the docs uh and you can also make uh documentation uh contribute to the documentation. Uh though that's more like uh I don't know if that's worthy enough of a contribution, but definitely if you find any kind of gotches, you know, open up a PR and uh it's much, much appreciated. Let's do two two more things I want to talk about, which is how do you actually use this library and what are the use cases you can build using the API? Uh using the SDK. So, uh first thing is like how do you actually use this? So to use this, we've uh built a very neat kind of tool called um create Z app. So you can just go uh to the quick start and do NPX covalent HQ/create Z app. And what this does is it asks you about a bunch of questions. Right now there's one template, we'll soon have multiple templates and this creates a fully uh bootstrapped tool uh to create a ZEE. So, you know, it just gets everything out of the box. Now this is not very different from create React app or create Next app if you're familiar with those kinds of like um, you know, helper helper tools. So that's basically what's happening here. And then you get the whole source code and then you can like, you know, use the agent and so on. So this is something that's really really cool. And the final thing I want to talk about is what kind of contributions are we uh looking at? So, what we have here is something known as ZEE use cases. It's on the cxt.build uh documentation site. And you go here, uh there's a whole bunch of use cases that we've uh written uh on what we would love to be love to see built with the SDK. And so something like this is is meteor, something like this is, you know, uh worthy of a uh uh of a, you know, a grant and uh further, you know, investment. And so uh this is going to be almost not just using SDK, but also contributing to the SDK itself in terms of the tooling, in terms of the logic, in terms of like debugging. Uh maybe there's some specialized LLM that you require, uh maybe it's going to create a chart. So you need some kind of like uh you know, uh multimodal. Maybe it's uh uh maybe it's like like notebook LLM or something that that creates a podcast after it, you know, gives you a voice message, uh all kinds of things. So I think there's no limit to what you can build with this. So this is what makes it super, super exciting. So, good luck hackers. Uh I just want to leave you with one final thought. Uh I started covalent uh at a hackathon. So, you know, there was one one weekend, I was just able to sit down and uh build something in two days uh which was incredible and uh covalent has come a long way since that that uh one weekend. And I would really wish that uh for all of your projects to uh grow to this kind of scale. So just telling you that just because it seems like a hackathon project doesn't mean that it's a throwaway. It could be the start of something uh it could be you know that that kindle that uh lights up a big fire. So uh I wish you all the very best and uh happy hacking. Thank you.